# backend/api/stt.py

import os
import io
from pathlib import Path

from fastapi import APIRouter, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
from openai import OpenAI

# ----------------------------------------------------
# 1) í”„ë¡œì íŠ¸ ë£¨íŠ¸(ai_feedback_mvp/.env)ì—ì„œ .env ë¡œë“œ
#    stt.py ìœ„ì¹˜: ai_feedback_mvp/backend/api/stt.py
#    parents[2] => ai_feedback_mvp
# ----------------------------------------------------
ROOT_DIR = Path(__file__).resolve().parents[2]   # .../ai_feedback_mvp
ENV_PATH = ROOT_DIR / ".env"

print("=== DEBUG: ROOT_DIR ===", ROOT_DIR)
print("=== DEBUG: ENV PATH ===", ENV_PATH)

if ENV_PATH.exists():
    load_dotenv(ENV_PATH)
    print("=== DEBUG: .env ë¡œë“œë¨ ===")
else:
    print("=== DEBUG: .env íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ ===")

api_key = os.getenv("OPENAI_API_KEY")
print(
    "=== DEBUG: LOADED API KEY (first 10 chars) ===",
    api_key[:10] if api_key else "None",
)

if not api_key:
    raise RuntimeError("OPENAI_API_KEY not found after loading .env!")

# OpenAI í´ë¼ì´ì–¸íŠ¸ (main.pyì—ì„œ stt_clientë¡œë„ ì“°ê¸° ìœ„í•´ export)
client = OpenAI(api_key=api_key)

# FastAPI ë¼ìš°í„°
router = APIRouter(prefix="/api", tags=["stt"])


@router.post("/stt")
async def transcribe_audio(file: UploadFile = File(...)):
    """
    ìŒì„± íŒŒì¼ì„ Whisper STTë¡œ ë³€í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    - í”„ë¡ íŠ¸ì—ì„œëŠ” FormDataì˜ í•„ë“œ ì´ë¦„ì„ "file"ë¡œ ë³´ëƒ„
    """
    if not file or not file.content_type:
        raise HTTPException(
            status_code=400,
            detail="audio file required (field name: 'file')",
        )

    if not file.content_type.startswith("audio/"):
        raise HTTPException(
            status_code=400,
            detail=f"audio file required, got {file.content_type!r}",
        )

    try:
        audio_bytes = await file.read()
        audio_buffer = io.BytesIO(audio_bytes)
        audio_buffer.name = file.filename or "recording.webm"

        # ğŸ”¥ Whisper STT í˜¸ì¶œ
        resp = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_buffer,
            language="ko",
        )

        text = getattr(resp, "text", None)
        return JSONResponse({"transcript": text})

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"STT failed: {e}")
